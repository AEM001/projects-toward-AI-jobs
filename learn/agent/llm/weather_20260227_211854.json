{
  "initial_response": {
    "id": "chatcmpl-DDs20Hc1EDaE7yhSkFqybMYyBZ90m",
    "choices": [
      {
        "finish_reason": "tool_calls",
        "index": 0,
        "logprobs": null,
        "message": {
          "content": null,
          "refusal": null,
          "role": "assistant",
          "annotations": [],
          "audio": null,
          "function_call": null,
          "tool_calls": [
            {
              "id": "call_mZ2rIQ17sYfEiR3oechOyAwP",
              "function": {
                "arguments": "{\"location\":\"London\"}",
                "name": "get_weather"
              },
              "type": "function"
            }
          ]
        }
      }
    ],
    "created": 1772198332,
    "model": "gpt-4.1-nano-2025-04-14",
    "object": "chat.completion",
    "service_tier": null,
    "system_fingerprint": "fp_03e44fcc34",
    "usage": {
      "completion_tokens": 15,
      "prompt_tokens": 57,
      "total_tokens": 72,
      "completion_tokens_details": {
        "accepted_prediction_tokens": 0,
        "audio_tokens": 0,
        "reasoning_tokens": 0,
        "rejected_prediction_tokens": 0
      },
      "prompt_tokens_details": {
        "audio_tokens": 0,
        "cached_tokens": 0
      }
    }
  },
  "final_response": {
    "id": "chatcmpl-DDs22LgEQnJtPe7ewZKYjEfUMnhvi",
    "choices": [
      {
        "finish_reason": "stop",
        "index": 0,
        "logprobs": null,
        "message": {
          "content": "The current weather in London is cloudy with a temperature of 59\u00b0F.",
          "refusal": null,
          "role": "assistant",
          "annotations": [],
          "audio": null,
          "function_call": null,
          "tool_calls": null
        }
      }
    ],
    "created": 1772198334,
    "model": "gpt-4.1-nano-2025-04-14",
    "object": "chat.completion",
    "service_tier": null,
    "system_fingerprint": "fp_03e44fcc34",
    "usage": {
      "completion_tokens": 16,
      "prompt_tokens": 40,
      "total_tokens": 56,
      "completion_tokens_details": {
        "accepted_prediction_tokens": 0,
        "audio_tokens": 0,
        "reasoning_tokens": 0,
        "rejected_prediction_tokens": 0
      },
      "prompt_tokens_details": {
        "audio_tokens": 0,
        "cached_tokens": 0
      }
    }
  }
}